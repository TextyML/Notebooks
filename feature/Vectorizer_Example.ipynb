{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BaseEstimator:** Muss get_feature_names, fit und transform implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LinguisticVectorizer(BaseEstimator):\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return np.array(['sent_neut', 'sent_pos', 'sent_neg',\n",
    "                         'nouns', 'adjectives', 'verbs', 'adverbs',\n",
    "                         'allcaps', 'exclamation', 'question'])\n",
    "\n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "\n",
    "    def _get_sentiments(self, d):\n",
    "        # http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "        sent = tuple(nltk.word_tokenize(d))\n",
    "        if poscache is not None:\n",
    "            if d in poscache:\n",
    "                tagged = poscache[d]\n",
    "            else:\n",
    "                poscache[d] = tagged = nltk.pos_tag(sent)\n",
    "        else:\n",
    "            tagged = nltk.pos_tag(sent)\n",
    "\n",
    "        pos_vals = []\n",
    "        neg_vals = []\n",
    "\n",
    "        nouns = 0.\n",
    "        adjectives = 0.\n",
    "        verbs = 0.\n",
    "        adverbs = 0.\n",
    "\n",
    "        for w, t in tagged:\n",
    "            p, n = 0, 0\n",
    "            sent_pos_type = None\n",
    "            if t.startswith(\"NN\"):\n",
    "                sent_pos_type = \"n\"\n",
    "                nouns += 1\n",
    "            elif t.startswith(\"JJ\"):\n",
    "                sent_pos_type = \"a\"\n",
    "                adjectives += 1\n",
    "            elif t.startswith(\"VB\"):\n",
    "                sent_pos_type = \"v\"\n",
    "                verbs += 1\n",
    "            elif t.startswith(\"RB\"):\n",
    "                sent_pos_type = \"r\"\n",
    "                adverbs += 1\n",
    "\n",
    "            if sent_pos_type is not None:\n",
    "                sent_word = \"%s/%s\" % (sent_pos_type, w)\n",
    "\n",
    "                if sent_word in sent_word_net:\n",
    "                    p, n = sent_word_net[sent_word]\n",
    "\n",
    "            pos_vals.append(p)\n",
    "            neg_vals.append(n)\n",
    "\n",
    "        l = len(sent)\n",
    "        avg_pos_val = np.mean(pos_vals)\n",
    "        avg_neg_val = np.mean(neg_vals)\n",
    "\n",
    "        return [1 - avg_pos_val - avg_neg_val, avg_pos_val, avg_neg_val,\n",
    "                nouns / l, adjectives / l, verbs / l, adverbs / l]\n",
    "\n",
    "    def transform(self, documents):\n",
    "        obj_val, pos_val, neg_val, nouns, adjectives, verbs, adverbs = np.array(\n",
    "            [self._get_sentiments(d) for d in documents]).T\n",
    "\n",
    "        allcaps = []\n",
    "        exclamation = []\n",
    "        question = []\n",
    "\n",
    "        for d in documents:\n",
    "            allcaps.append(\n",
    "                np.sum([t.isupper() for t in d.split() if len(t) > 2]))\n",
    "\n",
    "            exclamation.append(d.count(\"!\"))\n",
    "            question.append(d.count(\"?\"))\n",
    "\n",
    "        result = np.array(\n",
    "            [obj_val, pos_val, neg_val, nouns, adjectives, verbs, adverbs, allcaps,\n",
    "             exclamation, question]).T\n",
    "\n",
    "        return result\n",
    "\n",
    "emo_repl = {\n",
    "    # positive emoticons\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",  # :D in lower case\n",
    "    \":dd\": \" good \",  # :DD in lower case\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "\n",
    "    # negative emoticons:\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":S\": \" bad \",\n",
    "    \":-S\": \" bad \",\n",
    "}\n",
    "\n",
    "emo_repl_order = [k for (k_len, k) in reversed(\n",
    "    sorted([(len(k), k) for k in list(emo_repl.keys())]))]\n",
    "\n",
    "re_repl = {\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
